{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fee8d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mh5py\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "# HDF5 neuroactivity explorer for t15 copy task\n",
    "# - Scans data/hdf5_data_final\n",
    "# - Summarizes structure (sessions, files, trials, attributes)\n",
    "# - Visualizes representative neural activity and global distributions\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "# -------------------------\n",
    "# Paths (robust to notebook cwd)\n",
    "# -------------------------\n",
    "\n",
    "def resolve_path(primary: str, fallback: str) -> Path:\n",
    "    p = Path(primary)\n",
    "    return p if p.exists() else Path(fallback)\n",
    "\n",
    "DATA_DIR = resolve_path('../data/hdf5_data_final', 'data/hdf5_data_final')\n",
    "CSV_PATH = resolve_path('../data/t15_copyTaskData_description.csv', 'data/t15_copyTaskData_description.csv')\n",
    "\n",
    "assert DATA_DIR.exists(), f\"Data directory not found: {DATA_DIR}\"\n",
    "assert CSV_PATH.exists(), f\"CSV not found: {CSV_PATH}\"\n",
    "\n",
    "b2txt_csv_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# -------------------------\n",
    "# Utilities\n",
    "# -------------------------\n",
    "\n",
    "def safe_decode(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (bytes, bytearray)):\n",
    "        try:\n",
    "            return x.decode('utf-8')\n",
    "        except Exception:\n",
    "            return str(x)\n",
    "    if isinstance(x, np.ndarray):\n",
    "        # Could be array of ints or bytes; try to interpret\n",
    "        if x.dtype.kind in {'i', 'u'}:\n",
    "            # Treat as ASCII/int-coded with zero-termination\n",
    "            zero_idx = np.where(x == 0)[0]\n",
    "            end = zero_idx[0] if len(zero_idx) > 0 else len(x)\n",
    "            return ''.join(chr(int(c)) for c in x[:end])\n",
    "        if x.dtype.kind in {'S', 'U', 'O'}:\n",
    "            # Byte string array, take first element\n",
    "            try:\n",
    "                return x.tobytes().decode('utf-8', errors='ignore')\n",
    "            except Exception:\n",
    "                try:\n",
    "                    return x.astype(str).item()\n",
    "                except Exception:\n",
    "                    return str(x)\n",
    "    return str(x)\n",
    "\n",
    "\n",
    "def list_hdf5_files(data_root: Path):\n",
    "    sessions = sorted([p for p in data_root.iterdir() if p.is_dir()])\n",
    "    files = []\n",
    "    for session_dir in sessions:\n",
    "        for fname in sorted(session_dir.glob('*.hdf5')):\n",
    "            files.append((session_dir.name, fname))\n",
    "    return files\n",
    "\n",
    "\n",
    "def summarize_h5_file(h5_path: Path):\n",
    "    summary = {\n",
    "        'path': str(h5_path),\n",
    "        'num_trials': 0,\n",
    "        'trial_keys': [],\n",
    "        'n_time_steps': [],\n",
    "        'feature_dims': [],\n",
    "        'blocks': [],\n",
    "        'sessions': [],\n",
    "        'trial_nums': [],\n",
    "        'seq_lens': [],\n",
    "    }\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        for key in f.keys():\n",
    "            g = f[key]\n",
    "            # Required dataset\n",
    "            if 'input_features' not in g:\n",
    "                continue\n",
    "            ds = g['input_features']\n",
    "            t_len = g.attrs.get('n_time_steps', ds.shape[0])\n",
    "            feat_dim = ds.shape[1] if ds.ndim >= 2 else 1\n",
    "            summary['num_trials'] += 1\n",
    "            summary['trial_keys'].append(key)\n",
    "            summary['n_time_steps'].append(int(t_len))\n",
    "            summary['feature_dims'].append(int(feat_dim))\n",
    "            summary['blocks'].append(int(g.attrs.get('block_num', -1)))\n",
    "            session_attr = g.attrs.get('session', '')\n",
    "            if isinstance(session_attr, (bytes, bytearray)):\n",
    "                session_attr = session_attr.decode('utf-8', errors='ignore')\n",
    "            summary['sessions'].append(session_attr)\n",
    "            summary['trial_nums'].append(int(g.attrs.get('trial_num', -1)))\n",
    "            if 'seq_len' in g.attrs:\n",
    "                summary['seq_lens'].append(int(g.attrs['seq_len']))\n",
    "            else:\n",
    "                summary['seq_lens'].append(None)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def print_dataset_tree(files):\n",
    "    print(f\"Data root: {DATA_DIR}\")\n",
    "    print(f\"CSV: {CSV_PATH}\")\n",
    "    print(f\"Sessions found: {len(sorted({s for s, _ in files}))}\")\n",
    "    by_session = defaultdict(list)\n",
    "    for session, fpath in files:\n",
    "        by_session[session].append(fpath)\n",
    "    for session in sorted(by_session.keys()):\n",
    "        print(f\"- {session} ({len(by_session[session])} files)\")\n",
    "        for fpath in by_session[session]:\n",
    "            print(f\"    • {fpath.name}\")\n",
    "\n",
    "\n",
    "def match_corpus_from_csv(session_str: str, block_num: int):\n",
    "    # session like 't15.2023.08.11' → date '2023-08-11'\n",
    "    try:\n",
    "        parts = session_str.split('.')\n",
    "        date = f\"{parts[1]}-{parts[2]}-{parts[3]}\"\n",
    "    except Exception:\n",
    "        return None\n",
    "    m = b2txt_csv_df[(b2txt_csv_df['Date'] == date) & (b2txt_csv_df['Block number'] == block_num)]\n",
    "    if len(m) == 0:\n",
    "        return None\n",
    "    return m['Corpus'].values[0]\n",
    "\n",
    "\n",
    "def load_example_trial(h5_path: Path, trial_key: str):\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        g = f[trial_key]\n",
    "        feats = g['input_features'][:]\n",
    "        meta = {\n",
    "            'n_time_steps': int(g.attrs.get('n_time_steps', feats.shape[0])),\n",
    "            'seq_len': int(g.attrs['seq_len']) if 'seq_len' in g.attrs else None,\n",
    "            'session': g.attrs.get('session', ''),\n",
    "            'block_num': int(g.attrs.get('block_num', -1)),\n",
    "            'trial_num': int(g.attrs.get('trial_num', -1)),\n",
    "            'sentence_label': safe_decode(g.attrs.get('sentence_label', None)),\n",
    "            'corpus': None,\n",
    "        }\n",
    "        if isinstance(meta['session'], (bytes, bytearray)):\n",
    "            meta['session'] = meta['session'].decode('utf-8', errors='ignore')\n",
    "        # Try to read optional fields\n",
    "        transcription = None\n",
    "        if 'transcription' in g:\n",
    "            transcription = safe_decode(g['transcription'][:])\n",
    "        elif 'seq_class_ids' in g:\n",
    "            transcription = safe_decode(g['seq_class_ids'][:])\n",
    "        meta['transcription'] = transcription\n",
    "        # Corpus mapping from CSV\n",
    "        meta['corpus'] = match_corpus_from_csv(meta['session'], meta['block_num'])\n",
    "    return feats, meta\n",
    "\n",
    "\n",
    "def visualize_overview(file_summaries):\n",
    "    # Aggregate\n",
    "    all_lengths = []\n",
    "    all_feat_dims = []\n",
    "    trials_per_file = []\n",
    "    for s in file_summaries:\n",
    "        all_lengths.extend([x for x in s['n_time_steps'] if x is not None])\n",
    "        all_feat_dims.extend([x for x in s['feature_dims'] if x is not None])\n",
    "        trials_per_file.append(s['num_trials'])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    # Trials per file\n",
    "    axes[0].bar(range(len(trials_per_file)), trials_per_file, color='#4C72B0')\n",
    "    axes[0].set_title('Trials per file')\n",
    "    axes[0].set_xlabel('File index')\n",
    "    axes[0].set_ylabel('# Trials')\n",
    "\n",
    "    # Time steps distribution\n",
    "    axes[1].hist(all_lengths, bins=30, color='#55A868')\n",
    "    axes[1].set_title('Distribution of n_time_steps across trials')\n",
    "    axes[1].set_xlabel('n_time_steps')\n",
    "    axes[1].set_ylabel('# Trials')\n",
    "\n",
    "    # Feature dim distribution\n",
    "    axes[2].hist(all_feat_dims, bins=20, color='#C44E52')\n",
    "    axes[2].set_title('Distribution of feature dimensions across trials')\n",
    "    axes[2].set_xlabel('feature_dim')\n",
    "    axes[2].set_ylabel('# Trials')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_trial(feats: np.ndarray, meta: dict, max_lines: int = 8, heatmap_max_features: int = 64):\n",
    "    T, D = feats.shape[:2]\n",
    "    title_bits = []\n",
    "    if meta.get('session'):\n",
    "        title_bits.append(str(meta['session']))\n",
    "    if meta.get('block_num') is not None:\n",
    "        title_bits.append(f\"block {meta['block_num']}\")\n",
    "    if meta.get('trial_num') is not None:\n",
    "        title_bits.append(f\"trial {meta['trial_num']}\")\n",
    "    title = ' | '.join(title_bits)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "    # Panel A: a few feature traces\n",
    "    ax1 = plt.subplot2grid((2, 3), (0, 0), colspan=2)\n",
    "    num_lines = min(max_lines, D)\n",
    "    for i in range(num_lines):\n",
    "        ax1.plot(feats[:, i], label=f'feat {i+1}', linewidth=1)\n",
    "    ax1.set_title(f'Feature traces (first {num_lines}/{D})\\n{title}')\n",
    "    ax1.set_xlabel('time (frames)')\n",
    "    ax1.set_ylabel('value')\n",
    "    if num_lines <= 12:\n",
    "        ax1.legend(ncol=2, fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Panel B: heatmap of features x time (subset)\n",
    "    ax2 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)\n",
    "    subset = feats[:, : min(heatmap_max_features, D)]\n",
    "    im = ax2.imshow(subset.T, aspect='auto', interpolation='nearest', cmap='viridis')\n",
    "    ax2.set_title(f'Heatmap (features x time)\\nshown: {subset.shape[1]}/{D} features')\n",
    "    ax2.set_xlabel('time (frames)')\n",
    "    ax2.set_ylabel('feature index')\n",
    "    plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Panel C: per-feature variance (first 32)\n",
    "    ax3 = plt.subplot2grid((2, 3), (1, 0), colspan=2)\n",
    "    k = min(32, D)\n",
    "    variances = np.var(feats[:, :k], axis=0)\n",
    "    ax3.bar(np.arange(k), variances, color='#8172B2')\n",
    "    ax3.set_title('Per-feature variance (first 32)')\n",
    "    ax3.set_xlabel('feature index')\n",
    "    ax3.set_ylabel('variance')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Textual meta\n",
    "    print('--- Trial metadata ---')\n",
    "    for name in ['session', 'block_num', 'trial_num', 'n_time_steps', 'seq_len', 'corpus', 'sentence_label', 'transcription']:\n",
    "        if name in meta and meta[name] is not None:\n",
    "            print(f\"{name}: {meta[name]}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Scan dataset and summarize\n",
    "# -------------------------\n",
    "files = list_hdf5_files(DATA_DIR)\n",
    "print_dataset_tree(files)\n",
    "\n",
    "file_summaries = [summarize_h5_file(p) for _, p in files]\n",
    "\n",
    "# Quick overall stats\n",
    "total_trials = sum(s['num_trials'] for s in file_summaries)\n",
    "feat_dims = Counter([d for s in file_summaries for d in s['feature_dims'] if d is not None])\n",
    "print(f\"\\nTotal files: {len(file_summaries)} | Total trials: {total_trials}\")\n",
    "print(f\"Feature dims observed (dim: count): {dict(feat_dims)}\")\n",
    "\n",
    "# Visualize overview distributions\n",
    "visualize_overview(file_summaries)\n",
    "\n",
    "# -------------------------\n",
    "# Visualize a representative trial\n",
    "# -------------------------\n",
    "example = None\n",
    "for (session, fpath), summary in zip(files, file_summaries):\n",
    "    if summary['num_trials'] > 0:\n",
    "        example = (fpath, summary['trial_keys'][0])\n",
    "        break\n",
    "\n",
    "if example is None:\n",
    "    print('No trials found in dataset.')\n",
    "else:\n",
    "    eg_path, eg_key = example\n",
    "    print(f\"\\nLoading example trial from: {eg_path.name} | key: {eg_key}\")\n",
    "    feats, meta = load_example_trial(eg_path, eg_key)\n",
    "    visualize_trial(feats, meta, max_lines=8, heatmap_max_features=64)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b2txt25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
